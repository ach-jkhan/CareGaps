{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb97860f-b944-4201-bbc6-b2aca4f7c70d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELL 1: Install Packages (Development)\n",
    "# ===================================================================\n",
    "\n",
    "%pip install \\\n",
    "    mlflow[databricks]>=2.16.0 \\\n",
    "    databricks-agents \\\n",
    "    databricks-openai \\\n",
    "    openai \\\n",
    "    pydantic \\\n",
    "    unitycatalog-ai \\\n",
    "    uv \\\n",
    "    --upgrade --quiet\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14c04efc-d90d-4dd0-be7b-005258badf86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Clean up unsuccessfully deployed versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12cdc93d-6b96-4489-ab82-14204b04c9bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELL 2: Clean Up Old Versions (Optional)\n",
    "# ===================================================================\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "UC_MODEL_NAME = \"dev_kiddo.silver.CareGapsModel\"\n",
    "\n",
    "# Delete failed conda versions\n",
    "failed_versions = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "\n",
    "for version in failed_versions:\n",
    "    try:\n",
    "        client.delete_model_version(UC_MODEL_NAME, str(version))\n",
    "        print(f\"✓ Deleted version {version}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Version {version}: already deleted or doesn't exist\")\n",
    "\n",
    "print(\"\\n✓ Cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e847562-14bf-439b-8298-dc2066be9114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# LOG Model with pre-deployent check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91c5c4d2-e756-4a18-8401-d6a751bf4945",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# ===================================================================\n# VALIDATED DEPLOYMENT WITH PRE-DEPLOYMENT CHECK\n# ===================================================================\n\nimport mlflow\nfrom mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n\nmlflow.set_registry_uri(\"databricks-uc\")\n\nUC_MODEL_NAME = \"dev_kiddo.silver.CareGapsModel\"\nENDPOINT_NAME = \"agents_dev_kiddo-silver-CareGapsModel\"\nLLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n\n# Find agent.py\nimport os\nif os.path.exists(\"agent.py\"):\n    agent_path = \"agent.py\"\nelse:\n    agent_path = \"/Workspace/Users/adminjkhan@akronchildrens.org/CareGaps/CareGapAgents/agent.py\"\n\nprint(f\"Agent path: {agent_path}\")\nprint(f\"File exists: {os.path.exists(agent_path)}\")\n\n# Build resources for auth passthrough (UC functions + serving endpoint)\nUC_TOOL_NAMES = [\n    \"dev_kiddo.silver.get_top_providers\",\n    \"dev_kiddo.silver.get_patient_360\",\n    \"dev_kiddo.silver.get_gap_categories\",\n    \"dev_kiddo.silver.get_provider_gaps\",\n    \"dev_kiddo.silver.get_long_open_gaps\",\n    \"dev_kiddo.silver.get_outreach_needed\",\n    \"dev_kiddo.silver.get_appointments_with_gaps\",\n    \"dev_kiddo.silver.get_critical_gaps\",\n    \"dev_kiddo.silver.search_patients\",\n    \"dev_kiddo.silver.get_gaps_by_type\",\n    \"dev_kiddo.silver.get_gap_statistics\",\n    \"dev_kiddo.silver.get_department_summary\",\n    \"dev_kiddo.silver.get_gaps_by_age\",\n    \"dev_kiddo.silver.get_gaps_no_appointments\",\n    \"dev_kiddo.silver.get_patient_gaps\",\n    \"dev_kiddo.silver.get_campaign_statistics\",\n    \"dev_kiddo.silver.search_campaign_opportunities\",\n    \"dev_kiddo.silver.get_campaign_opportunities\",\n    \"dev_kiddo.silver.get_patient_campaign_history\",\n]\n\nresources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\nfor tool_name in UC_TOOL_NAMES:\n    resources.append(DatabricksFunction(function_name=tool_name))\n\nprint(f\"{'='*60}\")\nprint(\"STEP 1: LOG MODEL\")\nprint('='*60)\n\nif mlflow.active_run():\n    mlflow.end_run()\n\nwith mlflow.start_run(run_name=\"validated_deployment\"):\n    \n    model_info = mlflow.pyfunc.log_model(\n        name=\"agent\",\n        python_model=agent_path,\n        registered_model_name=UC_MODEL_NAME,\n        pip_requirements=[\n            \"mlflow[databricks]>=2.16.0\",\n            \"databricks-openai>=0.2.0\",\n            \"openai>=1.0.0\",\n            \"pydantic>=2.0.0\",\n            \"unitycatalog-ai>=0.1.0\",\n        ],\n        resources=resources,\n    )\n    \n    run_id = model_info.run_id\n    version = model_info.registered_model_version\n    \n    print(f\"✓ Model logged\")\n    print(f\"  Version: {version}\")\n    print(f\"  Run ID: {run_id}\")\n    print(f\"  Resources: {len(resources)} (1 endpoint + {len(UC_TOOL_NAMES)} UC functions)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4680289f-8df7-4482-b497-74880206a59e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "## Pre-Deployment Validation Suite\n\nValidates agent routing, response format, scope boundaries, and campaign handling.  \nTests are grouped into 6 categories matching the decision-tree in agent.py."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae1bf1fb-b375-4fde-9c9d-14abd5c83803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# ===================================================================\n# PRE-DEPLOYMENT VALIDATION SUITE\n# Tests decision-tree routing, response format, scope, and campaigns\n# ===================================================================\n\nimport mlflow\nimport time\nimport re\nimport json\nimport signal\nfrom mlflow.tracking import MlflowClient\n\nmlflow.set_registry_uri(\"databricks-uc\")\nclient = MlflowClient()\n\n# Get latest model\nmodel_versions = client.search_model_versions(\"name='dev_kiddo.silver.CareGapsModel'\")\nlatest = max(model_versions, key=lambda x: int(x.version))\nrun_id = latest.run_id\nmodel_uri = f\"runs:/{run_id}/agent\"\n\n# Max seconds per test (prevents infinite hangs)\nTEST_TIMEOUT = 300  # 5 minutes\n\nprint(f\"Testing model version {latest.version} (run: {run_id})\")\nprint(f\"Timeout per test: {TEST_TIMEOUT}s\")\nprint(f\"{'='*70}\\n\")\n\n\n# -------------------------------------------------------------------\n# Timeout handler\n# -------------------------------------------------------------------\nclass TestTimeout(Exception):\n    pass\n\ndef _timeout_handler(signum, frame):\n    raise TestTimeout(f\"Test exceeded {TEST_TIMEOUT}s timeout\")\n\n\n# -------------------------------------------------------------------\n# Helper: extract text from agent response\n# -------------------------------------------------------------------\ndef extract_text(response) -> str:\n    \"\"\"Extract readable text from ResponsesAgentResponse or raw dict.\"\"\"\n    if response is None:\n        return \"\"\n    if isinstance(response, str):\n        return response\n    if hasattr(response, \"output\"):\n        parts = []\n        for item in response.output:\n            if hasattr(item, \"text\"):\n                parts.append(item.text)\n            elif isinstance(item, dict) and \"text\" in item:\n                parts.append(item[\"text\"])\n        return \"\\n\".join(parts)\n    if isinstance(response, dict):\n        if \"output\" in response:\n            return extract_text(response[\"output\"])\n        return json.dumps(response, default=str)\n    if isinstance(response, list):\n        parts = []\n        for item in response:\n            if isinstance(item, dict) and \"text\" in item:\n                parts.append(item[\"text\"])\n            elif hasattr(item, \"text\"):\n                parts.append(item.text)\n        return \"\\n\".join(parts) if parts else str(response)\n    return str(response)\n\n\n# -------------------------------------------------------------------\n# Helper: run a single test with timeout\n# -------------------------------------------------------------------\ndef run_test(query: str) -> dict:\n    \"\"\"Run a query with timeout. Returns result dict.\"\"\"\n    start = time.time()\n    # Set alarm-based timeout (Unix only, works in Databricks)\n    old_handler = signal.signal(signal.SIGALRM, _timeout_handler)\n    signal.alarm(TEST_TIMEOUT)\n    try:\n        response = mlflow.models.predict(\n            model_uri=model_uri,\n            input_data={\"input\": [{\"role\": \"user\", \"content\": query}]},\n            env_manager=\"uv\",\n        )\n        signal.alarm(0)  # Cancel alarm\n        elapsed = time.time() - start\n        text = extract_text(response)\n        return {\"text\": text, \"elapsed\": elapsed, \"error\": None}\n    except TestTimeout:\n        elapsed = time.time() - start\n        return {\"text\": \"\", \"elapsed\": elapsed, \"error\": f\"TIMEOUT after {TEST_TIMEOUT}s\"}\n    except Exception as e:\n        signal.alarm(0)\n        elapsed = time.time() - start\n        return {\"text\": \"\", \"elapsed\": elapsed, \"error\": str(e)}\n    finally:\n        signal.signal(signal.SIGALRM, old_handler)\n\n\n# -------------------------------------------------------------------\n# Validation checks (reusable)\n# -------------------------------------------------------------------\ndef check_has_content(text, min_len=50):\n    ok = len(text) >= min_len\n    return ok, f\"Response length {len(text)} chars (min {min_len})\"\n\ndef check_has_table(text):\n    ok = \"|\" in text and \"---\" in text\n    return ok, \"Contains markdown table\" if ok else \"Missing markdown table\"\n\ndef check_has_next_actions(text):\n    ok = \"next best action\" in text.lower() or \"### next\" in text.lower()\n    return ok, \"Has Next Best Actions\" if ok else \"Missing Next Best Actions\"\n\ndef check_contains_any(text, keywords, label=\"\"):\n    found = [kw for kw in keywords if kw.lower() in text.lower()]\n    ok = len(found) > 0\n    desc = f\"Found: {found}\" if ok else f\"None of {keywords} found\"\n    return ok, f\"{label}: {desc}\" if label else desc\n\ndef check_not_contains(text, keywords, label=\"\"):\n    found = [kw for kw in keywords if kw.lower() in text.lower()]\n    ok = len(found) == 0\n    desc = \"Correctly absent\" if ok else f\"Unexpectedly found: {found}\"\n    return ok, f\"{label}: {desc}\" if label else desc\n\ndef check_redirects_to_dashboard(text):\n    ok = any(kw in text.lower() for kw in [\"campaign\", \"sidebar\", \"dashboard\", \"navigate\"])\n    return ok, \"Redirects to dashboard\" if ok else \"Missing dashboard redirect\"\n\n\n# ===================================================================\n# TEST DEFINITIONS (14 tests, 9 categories)\n# ===================================================================\ntests = []\n\n# --- Step 1: CAMPAIGN ROUTING ---\ntests.append({\n    \"id\": \"C1\", \"category\": \"Campaign Routing\",\n    \"query\": \"How is the flu vaccine piggybacking campaign going?\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_contains_any(t, [\"pending\", \"sent\", \"approved\", \"opportunities\", \"total\", \"campaign\"], \"Campaign data\"),\n        lambda t: check_not_contains(t, [\"gap_type\", \"care gap type\", \"well child\"], \"No care-gap leakage\"),\n    ],\n})\ntests.append({\n    \"id\": \"C2\", \"category\": \"Campaign Routing\",\n    \"query\": \"Show flu vaccine opportunities with asthma patients\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_has_table(t),\n        lambda t: check_contains_any(t, [\"asthma\", \"j45\"], \"Asthma reference\"),\n    ],\n})\ntests.append({\n    \"id\": \"C3\", \"category\": \"Campaign Routing\",\n    \"query\": \"Search for sibling vaccine opportunities at Beachwood\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_contains_any(t, [\"beachwood\", \"opportunity\", \"sibling\", \"campaign\", \"vaccine\"], \"Location search\"),\n    ],\n})\n\n# --- Step 2: PATIENT ROUTING ---\ntests.append({\n    \"id\": \"P1\", \"category\": \"Patient Routing\",\n    \"query\": \"Find patient 2886348\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_contains_any(t, [\"2886348\", \"patient\", \"mrn\"], \"Patient reference\"),\n    ],\n})\ntests.append({\n    \"id\": \"P2\", \"category\": \"Patient Routing\",\n    \"query\": \"Show me all gaps for patient 2886348\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_has_table(t),\n        lambda t: check_contains_any(t, [\"gap\", \"2886348\"], \"Patient gaps data\"),\n    ],\n})\n\n# --- Step 3: DEPARTMENT / PROVIDER ---\ntests.append({\n    \"id\": \"D1\", \"category\": \"Department Routing\",\n    \"query\": \"Which departments have the most open care gaps?\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_has_table(t),\n        lambda t: check_contains_any(t, [\"department\", \"dept\"], \"Department data\"),\n        lambda t: check_not_contains(t, [\"vaccine\", \"flu\", \"campaign\"], \"No campaign leakage\"),\n    ],\n})\ntests.append({\n    \"id\": \"D2\", \"category\": \"Provider Routing\",\n    \"query\": \"Show me the top providers by care gap count\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_has_table(t),\n        lambda t: check_contains_any(t, [\"provider\", \"dr\", \"md\"], \"Provider data\"),\n    ],\n})\n\n# --- Step 4: GAP TYPES ---\ntests.append({\n    \"id\": \"G1\", \"category\": \"Gap Types\",\n    \"query\": \"What are the top gap types by volume?\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_has_table(t),\n        lambda t: check_has_next_actions(t),\n    ],\n})\n\n# --- Step 5: URGENCY / OUTREACH ---\ntests.append({\n    \"id\": \"U1\", \"category\": \"Urgency / Outreach\",\n    \"query\": \"Show me critical care gaps that need immediate attention\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_has_table(t),\n        lambda t: check_contains_any(t, [\"critical\", \"urgent\", \"overdue\", \"high\"], \"Urgency indicators\"),\n    ],\n})\ntests.append({\n    \"id\": \"U2\", \"category\": \"Urgency / Outreach\",\n    \"query\": \"Show patients with gaps but no upcoming appointments\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_has_table(t),\n        lambda t: check_contains_any(t, [\"no appointment\", \"appointment\", \"patient\"], \"No-appointment data\"),\n    ],\n})\n\n# --- Step 6: GENERAL OVERVIEW ---\ntests.append({\n    \"id\": \"O1\", \"category\": \"General Overview\",\n    \"query\": \"How many care gaps are there overall?\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_contains_any(t, [\"total\", \"statistic\", \"gap\", \"open\", \"count\"], \"Statistics data\"),\n    ],\n})\n\n# --- SCOPE BOUNDARY ---\ntests.append({\n    \"id\": \"S1\", \"category\": \"Scope Boundary\",\n    \"query\": \"What is the weather in Akron today?\",\n    \"checks\": [\n        lambda t: check_contains_any(t, [\"care gap\", \"caregaps\", \"only help\", \"cannot\", \"can only\"], \"Scope rejection\"),\n    ],\n})\n\n# --- DASHBOARD REDIRECT ---\ntests.append({\n    \"id\": \"R1\", \"category\": \"Dashboard Redirect\",\n    \"query\": \"Approve the flu vaccine opportunity for MRN 12345\",\n    \"checks\": [\n        lambda t: check_redirects_to_dashboard(t),\n    ],\n})\n\n# --- RESPONSE FORMAT ---\ntests.append({\n    \"id\": \"F1\", \"category\": \"Response Format\",\n    \"query\": \"Show flu vaccine opportunities that are pending\",\n    \"checks\": [\n        lambda t: check_has_content(t),\n        lambda t: check_has_table(t),\n        lambda t: check_has_next_actions(t),\n        lambda t: check_not_contains(t, [\"function_call\", \"tool_call\", '{\"'], \"No raw JSON leaked\"),\n    ],\n})\n\n\n# ===================================================================\n# RUN ALL TESTS\n# ===================================================================\nresults = []\ntotal_pass = 0\ntotal_fail = 0\n\nfor test in tests:\n    tid = test[\"id\"]\n    cat = test[\"category\"]\n    query = test[\"query\"]\n\n    print(f\"[{tid}] {cat}\")\n    print(f\"  Query: {query}\")\n\n    result = run_test(query)\n\n    if result[\"error\"]:\n        print(f\"  ERROR: {result['error']} ({result['elapsed']:.1f}s)\")\n        total_fail += 1\n        results.append({\"id\": tid, \"category\": cat, \"status\": \"FAIL\", \"reason\": result[\"error\"]})\n        print()\n        continue\n\n    text = result[\"text\"]\n    elapsed = result[\"elapsed\"]\n    print(f\"  Response: {len(text)} chars in {elapsed:.1f}s\")\n    print(f\"  Preview: {text[:120]}...\")\n\n    check_results = []\n    test_passed = True\n    for check_fn in test[\"checks\"]:\n        ok, msg = check_fn(text)\n        symbol = \"PASS\" if ok else \"FAIL\"\n        check_results.append((ok, msg))\n        print(f\"    [{symbol}] {msg}\")\n        if not ok:\n            test_passed = False\n\n    if test_passed:\n        total_pass += 1\n        results.append({\"id\": tid, \"category\": cat, \"status\": \"PASS\", \"elapsed\": elapsed})\n    else:\n        total_fail += 1\n        failed_checks = [msg for ok, msg in check_results if not ok]\n        results.append({\"id\": tid, \"category\": cat, \"status\": \"FAIL\", \"reason\": \"; \".join(failed_checks)})\n\n    print()\n\n\n# ===================================================================\n# SUMMARY\n# ===================================================================\nprint(\"=\" * 70)\nprint(\"VALIDATION SUMMARY\")\nprint(\"=\" * 70)\nprint(f\"\\n  Total:   {len(tests)}\")\nprint(f\"  Passed:  {total_pass}\")\nprint(f\"  Failed:  {total_fail}\")\nprint(f\"  Rate:    {100*total_pass/len(tests):.0f}%\\n\")\n\nif total_fail > 0:\n    print(\"FAILED TESTS:\")\n    for r in results:\n        if r[\"status\"] == \"FAIL\":\n            print(f\"  [{r['id']}] {r['category']}: {r.get('reason', '')}\")\n    print()\n\nif total_fail == 0:\n    print(\">>> ALL TESTS PASSED - SAFE TO DEPLOY <<<\")\nelse:\n    print(f\">>> {total_fail} TEST(S) FAILED - REVIEW BEFORE DEPLOYING <<<\")\n\nprint(\"=\" * 70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63b3b9ac-8d75-4c6d-8a08-87cabf42b232",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent as serving endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82d26765-cf92-445d-bd60-164f7192b426",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 3: DEPLOY TO SERVING ENDPOINT\n",
    "# ============================================================\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import ServedEntityInput, EndpointCoreConfigInput\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Configuration\n",
    "UC_MODEL_NAME = \"dev_kiddo.silver.CareGapsModel\"\n",
    "ENDPOINT_NAME = \"agents_dev_kiddo-silver-CareGapsModel\"\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"DEPLOYING AGENT TO SERVING ENDPOINT\")\n",
    "print('='*60)\n",
    "\n",
    "# Get latest registered version\n",
    "client = MlflowClient()\n",
    "model_versions = client.search_model_versions(f\"name='{UC_MODEL_NAME}'\")\n",
    "latest_version = max(model_versions, key=lambda x: int(x.version))\n",
    "\n",
    "print(f\"\\nModel: {UC_MODEL_NAME}\")\n",
    "print(f\"Version: {latest_version.version}\")\n",
    "print(f\"Endpoint: {ENDPOINT_NAME}\\n\")\n",
    "\n",
    "# Create WorkspaceClient\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Create served entity using SDK class\n",
    "served_entity = ServedEntityInput(\n",
    "    entity_name=UC_MODEL_NAME,\n",
    "    entity_version=str(latest_version.version),\n",
    "    workload_size=\"Small\",\n",
    "    scale_to_zero_enabled=False,\n",
    ")\n",
    "\n",
    "print(\"Deploying...\")\n",
    "\n",
    "try:\n",
    "    # Try to update existing endpoint\n",
    "    w.serving_endpoints.update_config(\n",
    "        name=ENDPOINT_NAME,\n",
    "        served_entities=[served_entity],\n",
    "    )\n",
    "    print(f\"✓ Updated existing endpoint\")\n",
    "    \n",
    "except Exception as e:\n",
    "    error_msg = str(e)\n",
    "    \n",
    "    if \"RESOURCE_DOES_NOT_EXIST\" in error_msg or \"does not exist\" in error_msg.lower():\n",
    "        # Create new endpoint if it doesn't exist\n",
    "        print(\"Endpoint doesn't exist, creating...\")\n",
    "        \n",
    "        w.serving_endpoints.create(\n",
    "            name=ENDPOINT_NAME,\n",
    "            config=EndpointCoreConfigInput(\n",
    "                name=ENDPOINT_NAME,\n",
    "                served_entities=[served_entity]\n",
    "            )\n",
    "        )\n",
    "        print(f\"✓ Created new endpoint\")\n",
    "    else:\n",
    "        print(f\"✗ Deployment failed: {error_msg}\")\n",
    "        raise\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"✓✓✓ DEPLOYMENT INITIATED ✓✓✓\")\n",
    "print('='*60)\n",
    "print(f\"\\nEndpoint: {ENDPOINT_NAME}\")\n",
    "print(f\"Version: {latest_version.version}\")\n",
    "print(f\"\\nContainer build will take 3-5 minutes...\")\n",
    "print(f\"Monitor at: Serving > Endpoints > {ENDPOINT_NAME}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "caregaps-small_driver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}